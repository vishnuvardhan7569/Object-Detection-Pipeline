# ğŸ—‘ï¸ Trash Object Detection System (YOLOv5 + ONNX + FastAPI)

An **end-to-end object detection pipeline** for identifying trash and plastic waste items using **YOLOv5**, optimized with **ONNX**, benchmarked on **CPU**, and deployed as a **FastAPI inference service**.

This project demonstrates the **complete ML lifecycle**:
dataset â†’ training â†’ evaluation â†’ optimization â†’ benchmarking â†’ deployment.

---

## ğŸš€ Project Highlights

* âœ… Trained **YOLOv5** on the **TACO Trash Dataset**
* âœ… Achieved **mAP@50 â‰ˆ 0.34** on 18 waste classes
* âœ… Exported model to **ONNX** for faster CPU inference
* âœ… Benchmarked **PyTorch vs ONNX** on CPU
* âœ… Built **FastAPI REST API** for real-time inference
* âœ… Auto-rescaled bounding boxes to original image size
* âœ… Visual output with drawn bounding boxes

---

## ğŸ§  Classes Detected (18)

Examples:

* Plastic bag / wrapper
* Bottle, Bottle cap
* Can, Carton
* Paper
* Cigarette
* Cup, Lid
* Straw
* Styrofoam piece
* Other litter, Other plastic
  â€¦and more.

---

## ğŸ—‚ï¸ Folder Structure

```
Object Detection/
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ taco-yolo.ipynb     # Training + evaluation + export
â”‚
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ benchmark_pytorch_cpu.py
â”‚   â”œâ”€â”€ benchmark_onnx_cpu.py
â”‚   â”œâ”€â”€ best.pt
â”‚   â””â”€â”€ best.onnx
|
â”œâ”€â”€ yolov5_fastapi/
â”‚   â”œâ”€â”€ app.py                   # FastAPI application
â”‚   â”œâ”€â”€ best.onnx                # ONNX model for inference
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“¦ Dataset

* **Dataset**: TACO â€“ Trash Annotations in Context
* **Format**: YOLO
* **Source**: Kaggle
* **Classes**: 18
* **Splits**:

  * Train
  * Validation
  * Test

Dataset was **used directly from Kaggle Input (read-only)**.

---

## ğŸ§ª Work Done in Kaggle Notebook

All heavy ML tasks were performed in **Kaggle (GPU)**:

### 1ï¸âƒ£ Dataset Preparation

* Used YOLO-format dataset (`train/`, `valid/`, `test/`)
* Verified `data.yaml` paths and class names

### 2ï¸âƒ£ Training YOLOv5

```bash
python train.py \
  --img 640 \
  --batch 16 \
  --epochs 30 \
  --data data.yaml \
  --weights yolov5s.pt \
  --name taco_yolov5 \
  --cache ram
```

### 3ï¸âƒ£ Model Evaluation

* Precision, Recall, mAP calculated per class
* AutoAnchor optimization applied
* Best weights saved as `best.pt`

### 4ï¸âƒ£ Export to ONNX

```bash
python export.py \
  --weights runs/train/taco_yolov55/weights/best.pt \
  --include onnx
```

Output:

```
best.onnx (â‰ˆ27 MB)
```

---

## ğŸ“Š Benchmark Results (CPU â€“ VS Code)

Benchmarks were done **locally on CPU** using the same image resolution (640Ã—640).

| Model   | Avg Inference Time | FPS   |
| ------- | ------------------ | ----- |
| PyTorch | 120.88 ms          | 8.27  |
| ONNX    | 49.53 ms           | 20.19 |

âœ… **ONNX is ~2.4Ã— faster than PyTorch on CPU**

---

## ğŸŒ FastAPI Inference Service

### ğŸ”¹ Features

* CPU-based ONNX inference
* Automatic bounding box rescaling
* JSON response endpoint
* Image output endpoint with drawn boxes

### ğŸ”¹ Endpoints

#### `POST /detect`

Returns detections as JSON.

```json
{
  "count": 3,
  "detections": [
    {
      "class": "Can",
      "confidence": 0.973,
      "bbox": [177, 97, 139, 126]
    }
  ]
}
```

#### `POST /detect-image`

Returns the image with bounding boxes drawn.

---

## â–¶ï¸ Running the API Locally

```bash
cd yolov5_fastapi
pip install -r requirements.txt
uvicorn app:app --reload
```

Open Swagger UI:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ–¼ï¸ Sample Output

* Bounding boxes drawn in **green**
* Label + confidence shown
* Boxes correctly mapped to **original image size**

---

## ğŸ§© Technologies Used

* **Python**
* **YOLOv5**
* **PyTorch**
* **ONNX**
* **ONNX Runtime**
* **FastAPI**
* **OpenCV**
* **NumPy**
* **Kaggle GPU**
* **VS Code (CPU benchmarking)**

---

## ğŸ¯ Key Learning Outcomes

* End-to-end object detection workflow
* Model optimization using ONNX
* CPU performance benchmarking
* Production-style API deployment
* Handling real-world datasets
* Clean separation of training and inference environments

---

## ğŸ“Œ Future Enhancements

* Docker containerization
* GPU inference support
* Video stream detection
* Cloud deployment (AWS / Azure / GCP)
* Frontend dashboard

---

## ğŸ‘¤ Author

**Vishnu Vardhan Reddy**
Engineering Student | Full Stack & ML Enthusiast
